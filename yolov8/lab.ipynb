{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "\n",
      "model loading mem before: 0G\n",
      "model loading: 0:00:00.025753\n",
      "model loading mem after: 0G \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "idx = 3\n",
    "\n",
    "exps = [\n",
    "    \"2-1 Our Aug+v8 Aug\",\n",
    "    \"2-2 Our Aug+v8 Aug + Gussian\",\n",
    "    \"2-3 Our Aug+v8 Aug+ Normalize\",\n",
    "    \"2-4 Our Aug+v8 Aug + Gussian + Normalize\",\n",
    "]\n",
    "model = YOLO(f'/home/raymond0920/yolov8_xiang/result epoch 6000/{exps[idx]}/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model to device:cuda:0 0:00:00.063479\n",
      "model fuse 0:00:00.088307\n",
      "\n",
      "0: 1024x1024 2 yellows, 2 reds, 2 blues, 1: 1024x1024 21 yellows, 31 reds, 51 blues, 2: 1024x1024 12 yellows, 35 reds, 69 blues, 3: 1024x1024 11 yellows, 35 reds, 64 blues, 4: 1024x1024 6 yellows, 34 reds, 77 blues, 5: 1024x1024 2 yellows, 5 reds, 14 blues, 6: 1024x1024 2 yellows, 3 reds, 8 blues, 7: 1024x1024 11 yellows, 14 reds, 41 blues, 8: 1024x1024 18 yellows, 29 reds, 71 blues, 9: 1024x1024 11 yellows, 17 reds, 38 blues, 10: 1024x1024 6 yellows, 3 reds, 22 blues, 11: 1024x1024 8 yellows, 22 reds, 67 blues, 12: 1024x1024 1 yellow, 2 reds, 4 blues, 13: 1024x1024 4 yellows, 19 reds, 43 blues, 14: 1024x1024 17 yellows, 27 reds, 54 blues, 15: 1024x1024 12 yellows, 15 reds, 36 blues, 16: 1024x1024 1 yellow, 22 reds, 52 blues, 17: 1024x1024 1 yellow, 11 reds, 32 blues, 18: 1024x1024 14 yellows, 30 reds, 77 blues, 19: 1024x1024 1 yellow, 9 reds, 19 blues, 20: 1024x1024 1 yellow, 2 reds, 9 blues, 21: 1024x1024 1 yellow, 6 reds, 29 blues, 22: 1024x1024 1 yellow, 2 reds, 7 blues, 23: 1024x1024 9 yellows, 33 reds, 73 blues, 24: 1024x1024 12 yellows, 32 reds, 72 blues, 25: 1024x1024 20 yellows, 34 reds, 50 blues, 26: 1024x1024 3 yellows, 19 reds, 59 blues, 27: 1024x1024 10 yellows, 38 reds, 76 blues, 28: 1024x1024 1 yellow, 14 reds, 28 blues, 29: 1024x1024 5 yellows, 22 reds, 56 blues, 30: 1024x1024 2 yellows, 14 reds, 34 blues, 31: 1024x1024 4 yellows, 3 reds, 24 blues, 32: 1024x1024 9 yellows, 31 reds, 80 blues, 33: 1024x1024 4 yellows, 2 reds, 27 blues, 34: 1024x1024 4 yellows, 16 reds, 54 blues, 35: 1024x1024 5 yellows, 3 reds, 27 blues, 36: 1024x1024 2 yellows, 5 reds, 13 blues, 37: 1024x1024 2 yellows, 13 reds, 31 blues, 38: 1024x1024 4 yellows, 6 reds, 30 blues, 39: 1024x1024 6 reds, 12 blues, 40: 1024x1024 11 yellows, 33 reds, 65 blues, 41: 1024x1024 1 yellow, 4 reds, 7 blues, 42: 1024x1024 15 yellows, 37 reds, 65 blues, 43: 1024x1024 9 yellows, 26 reds, 58 blues, 44: 1024x1024 3 yellows, 7 reds, 11 blues, 103.6ms\n",
      "Speed: 3.3ms preprocess, 2.3ms inference, 5.1ms postprocess per image at shape (1, 3, 1024, 1024)\n"
     ]
    }
   ],
   "source": [
    "results = model.predict([f\"./3d_data_preprocess/{f}\" for f in os.listdir(\"./3d_data_preprocess\")], imgsz=1024, epochs=6000, patience=3000, workers=0, batch=2, pretrained=True, \n",
    "            hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=180, translate=0.5, scale=0, shear=0, perspective=0, flipud=0.5, fliplr=0.5, mosaic=1.0, mixup=0.5, copy_paste=0,\n",
    "            conf=0.3, max_det=3000, single_cls=False, seed=0,half=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "video = cv2.VideoWriter('./3d_predict/yolov8/video.mp4',cv2.VideoWriter.fourcc(*\"XVID\"),10,(720,720))\n",
    "\n",
    "def get_num(path):\n",
    "    return int(os.path.splitext(os.path.basename(path))[0])\n",
    "\n",
    "for idx, r in enumerate(sorted(results, key=lambda r: get_num(r.path))):\n",
    "    img_name = os.path.basename(r.path)\n",
    "    img_n, img_t = os.path.splitext(img_name)\n",
    "    \n",
    "    r.orig_img = cv2.imread(f'./3d_data/{str(img_n).zfill(5)}.tiff')\n",
    "    im_array = r.plot()  # plot a BGR numpy array of predictions\n",
    "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "    video.write(im_array)\n",
    "    im.save(f'./3d_predict/yolov8/{os.path.basename(r.path)}')  # save image\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"/home/raymond0920/yolov8_xiang/3d_test.txt\", 'w') as f:\n",
    "    f.writelines([f\"/home/raymond0920/yolov8_xiang/3d_data_preprocess/{img}\\n\" for img in os.listdir(\"/home/raymond0920/yolov8_xiang/3d_data_preprocess\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "def get_num(path):\n",
    "    return int(os.path.splitext(os.path.basename(path))[0])\n",
    "\n",
    "video = cv2.VideoWriter('./3d_predict/yolov7/video.mp4',cv2.VideoWriter.fourcc(*\"XVID\"),10,(720,720))\n",
    "colors = [(0,255,255), (0,0,255), (255,0,0)]\n",
    "\n",
    "def plot_one_box(x, img, color=None, label=None, line_thickness=1):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "\n",
    "for label in sorted(os.listdir(\"/home/raymond0920/yolov7_xiang/yolov7-main/runs/test/3d_test/labels\"), key=lambda p:get_num(p)):\n",
    "    idx = label.split('.')[0]\n",
    "    img = cv2.imread(f'./3d_data/{idx.zfill(5)}.tiff')\n",
    "    ih, iw, _ = img.shape\n",
    "    \n",
    "    with open(f\"/home/raymond0920/yolov7_xiang/yolov7-main/runs/test/3d_test/labels/{label}\") as f:\n",
    "        labels = [line.split() for line in f.readlines()]\n",
    "        labels = [(int(cls), ((float(x)-float(w)/2)*iw, (float(y)-float(h)/2)*ih, (float(x)+float(w)/2)*iw, (float(y)+float(h)/2)*ih), float(conf)) for (cls, x ,y ,w ,h, conf) in labels]\n",
    "    for cls, box, conf in labels:\n",
    "        if conf > 0.25:\n",
    "            plot_one_box(box,img, color=colors[cls])\n",
    "\n",
    "    video.write(img)\n",
    "    im = Image.fromarray(img[..., ::-1])\n",
    "    im.save(f'./3d_predict/yolov7/{idx}.jpg')\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
